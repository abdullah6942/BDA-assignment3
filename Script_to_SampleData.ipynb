{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "IBB_Le9Yba4Z"
      },
      "outputs": [],
      "source": [
        "import json # Importing the json module to work with JSON data\n",
        "import os # Importing the os module for interacting with the OS\n",
        "from tqdm import tqdm # Importing tqdm for progress bar\n",
        "\n",
        "# Function to sample the data\n",
        "def sample_json(input_file, output_file, target_size_gb, filter_key='also_buy'):\n",
        "# Convert the target size from gigabytes to bytes\n",
        "  target_size_bytes = target_size_gb * 1024**3\n",
        "# Initialize the current size of the output file in bytes\n",
        "  current_size_bytes = 0\n",
        "\n",
        "  # Open the input file in read mode and the output file in write mode\n",
        "  with open(input_file, 'r', encoding='utf-8') as infile, open(output_file, 'w', encoding='utf-8') as outfile:\n",
        "    # Loop over each line in the input file\n",
        "    for line in tqdm(infile): # Wrap infile with tqdm for progress bar\n",
        "    # Load the JSON data from the current line\n",
        "      record = json.loads(line)\n",
        "      # Check if the filter key exists and is not empty in the current record\n",
        "      if record.get(filter_key):\n",
        "        # If it exists, write the record to the output file and add a newline\n",
        "        outfile.write(json.dumps (record) + '\\n')\n",
        "        # Add the size of the current line to the current size of the output file\n",
        "        current_size_bytes += len(line.encode('utf-8'))\n",
        "\n",
        "      # If the current size of the output file is greater than or equal to the target size\n",
        "      if current_size_bytes >= target_size_bytes:\n",
        "        # Stop writing to the output file\n",
        "        break\n",
        "  # Print the final size of the output file in gigabytes\n",
        "  print(f\"Finished sampling. Output size: {current_size_bytes / 1024**3:.2f} GB\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_json('All_Amazon_Meta.json', 'Sampled_Amazon_Meta.json', 15)"
      ],
      "metadata": {
        "id": "G_DGZ44tbcKx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}